##############################
# IMPORT SPREADSHEET FORMAT  #
##############################

'''
tab: file_imports
columns: file_name	file_tab_name	import_from_row	output_table_name	key_column_name	key_column_value

tab: column_map
columns: output_table_name	original_column_name	rename_column_to	correct_values_list	add_values_to_master_list

tab: add_columns
columns: output_table_name	existing_column_name	create_new_column_name	search_string	value_if_true	value_if_false	duplicate_existing_column

tab: correct_values
columns: correct_values_list	change_from	change_to
'''


###################
# PYTHON PACKAGES #
###################

# pandas
import pandas as pd
import pandas
pandas.set_option('display.max_colwidth', 40000)
pandas.set_option('expand_frame_repr', False) # Stops it doing line breaks when printing to log

#from urllib import parse
from sqlalchemy import create_engine # used for sqlite as well
#from sqlalchemy.sql import text

# sqlite database
import sqlite3
import os
import csv


#############
# FUNCTIONS #
#############


#############################
# sqlite database functions #
#############################

# SQLAlechemy to SQLITE 
def dataframe_to_sqlite(database_path, dataframe_name, table_name, unique_rows):

    #if table name is blank, make it the same name as the dataframe
    tn = table_name
    if tn == '':
        tn = dataframe_name

    #has to be in localfiles as SQLITE freaks out on network drives: add this (/home/azureuser/localfiles/)
    #engine = create_engine(f'sqlite:////home/azureuser/localfiles/{database_path}', echo=False)
    #sqlite_connection = engine.connect()


    df = eval(dataframe_name)
    df.columns = df.columns.str.lower()      # convert all column names to lowercase

    if 'y' in unique_rows.lower():
        print('DROP DUPES')
        df = df.drop_duplicates()

    print('connecting...')

    # Create SQL from dataframe
    df.to_sql(tn, con, if_exists='replace',index=False)    # replaces the table

    print('data inserted')

    # print the number of rows imported
    rc_sql = 'select count(*) as num_rows from {}'.format(tn)
    row_count = pandas.read_sql_query(rc_sql, con)
    row_count = row_count.iloc[0]['num_rows']
    print(tn,'...rows imported: ',row_count)    


###################################         
#   sqlite settings variables     #
###################################

# Set the folder for where the input, output and database files will be saved
username = os.getlogin()
datapath = f"C:/Users/{username}/YOUR_FILEPATH/FOLDER"
datafiles = f"{datapath}/YOUR_DATABASE_PATH/"

# set the connection to the SQLITE database
sqlite_database_name = "YOUR_DATABASE_NAME"
con = sqlite3.connect(f"{datapath}/python/sqlite/{sqlite_database_name}.sqlite3")
cursor = con.cursor()



###########################
# data cleaning functions #
###########################

# function to import an excel and clean up the column names
def import_excel (this_path, this_file, this_sheet, start_from_row):

    # import the excel file
    df = pd.read_excel(this_path+this_file, sheet_name=this_sheet, header=start_from_row)
    
    # clean the column names
    df.columns = df.columns.str.replace('%', 'p',regex=True)  # replace percentage with 'p'
    df.columns = df.columns.str.replace('\$', 'd',regex=True)  # replace dollar sign with 'd'
    df.columns = df.columns.str.replace('[^a-zA-Z0-9]', ' ',regex=True)  # replace non-alpha-numeric with sapces
    df.columns = df.columns.str.strip() # remove spaces at start and end
    df.columns = df.columns.str.lower() # lowercase column names
    df.columns = df.columns.str.replace(' +', '_',regex=True) # replace multiple spaces with a single underscore
    df.columns = df.columns.str.replace(' ', '_',regex=True) # replace space with underscore
    df.columns = df.columns.str.replace('_+', '_',regex=True) # replace multiple spaces with a single underscore

    return df



### END OF SETUP  ###


#########################################################
#               IMPORT SETTINGS SPREADSHEET             #
#########################################################

# IMPORT FILE WHICH CONTAINS ALL INFO NEEDED TO IMPORT AND CLEAN INPUT FILES

# Call the function to import Excel'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', which contains all the other files which need importing, changes and qa information
# import_excel(file_path, file_name, excel_sheet_name, import_from_row)

# list of files to be imported, import information (e.g. which excel tab to import and from which row in the tab)), output table name, and primary keys 
file_imports = import_excel(f"{datafiles}", 'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', 'file_imports', 0) 

# columns which need to be renamed, which master-list of correct values need to be applied, and whether the column values need to be added to a master-list
column_map = import_excel(f"{datafiles}", 'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', 'column_map', 0) 

# correct value list name, as well as change from and change to values (e.g "Greater Sydney" gets changed to "Sydney")
correct_values = import_excel(f"{datafiles}", 'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', 'correct_values', 0) 

# columns to add (e.g create a flag column based on a conditions)
add_columns = import_excel(f"{datafiles}", 'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', 'add_columns', 0) 




#########################################################
#               CREATE DYNAMIC IMPORT CODE              #
#########################################################

dynamic_code = pandas.DataFrame(columns=['run_order', 'code'])
dynamic_code['run_order'] = dynamic_code['run_order'].astype(int)



#########################################################
#                   IMPORT SPREADSHEETS                 #
#########################################################
dynamic_code.loc[len(dynamic_code.index)] = [99, '# IMPORT STEPS']
dynamic_code.loc[len(dynamic_code.index)] = [798, ' ']
dynamic_code.loc[len(dynamic_code.index)] = [799, '# COPY CLEANED DATAFRAMES INTO SQLITE #']


# Based on the 'file_imports' sheet in 'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', generate the function calls needed to import the data files
for i in range(len(file_imports)):
    this_file = file_imports['file_name'][i]
    this_tab = file_imports['file_tab_name'][i]
    this_from_row = file_imports['import_from_row'][i]
    this_output_name = file_imports['output_table_name'][i]

    # import to dataframe        
    this_string = f"{this_output_name} = import_excel('{datafiles}','{this_file}','{this_tab}',{this_from_row})"
    dynamic_code.loc[len(dynamic_code.index)] = [i+100, this_string]

    # write dataframe to the database
    this_string = f"dataframe_to_sqlite ('{sqlite_database_name}', '{this_output_name}','','')"
    dynamic_code.loc[len(dynamic_code.index)] = [i+800, this_string]

    del this_file
    del this_tab
    del this_from_row
    del this_output_name
    del this_string


#########################################################
#                    RENAME COLUMNS                     #
#########################################################

dynamic_code.loc[len(dynamic_code.index)] = [298, ' ']
dynamic_code.loc[len(dynamic_code.index)] = [299, '# RENAME COLUMNS']

# convert original column name so it will match processed dataframe rules
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.replace('%', 'p', regex = True)    				# replace percentage with 'p'
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.replace('\$', 'd', regex = True)    			# replace dollar sign with 'd'
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.replace('[^a-zA-Z0-9]', ' ', regex =  True)     # replace non-alpha-numeric with spaces (except for ones chages as two rows above this)
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.strip() 										# remove spaces at start and end
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.lower() 										# lowercase column names
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.replace(' +', '_', regex = True)    			# replace multiple spaces with a single underscore
column_map['original_column_name'] = column_map['original_column_name'].astype(str).str.replace(' ', '_', regex = True)     			# replace space with underscore

# convert new column name so it will match processed dataframe rules
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.replace('%', 'p', regex = True)    						# replace percentage with 'p'
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.replace('\$', 'd', regex = True)    					# replace dollar sign with 'd'
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.replace('[^a-zA-Z0-9]', ' ', regex = True)     			# replace non-alpha-numeric with sapces
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.strip() 												# remove spaces at start and end
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.lower()  												# lowercase column names
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.replace(' +', '_', regex = True)      					# replace multiple spaces with a single underscore
column_map['rename_column_to'] = column_map['rename_column_to'].astype(str).str.replace(' ', '_', regex = True)     					# replace space with underscore

# Based on the 'column_map' sheet of 'YOUR_EXCEL_IMPORT_SPREADSHEET.xlsx', generate rename the columns code
for i in range(len(column_map)):
    this_output_table_name = column_map['output_table_name'][i]  
    this_original_column_name = column_map['original_column_name'][i]  
    this_rename_column_to = column_map['rename_column_to'][i]  
    this_correct_values_list = column_map['correct_values_list'][i]

    this_string = f"{this_output_table_name}.rename(columns = ^<'{this_original_column_name}':'{this_rename_column_to}'^>, inplace = True)"
    this_string = this_string.replace("^<","{")
    this_string = this_string.replace("^>","}")
    
    if str(this_rename_column_to) != 'nan':
        dynamic_code.loc[len(dynamic_code.index)] = [i+300, this_string]   

    del this_output_table_name
    del this_original_column_name
    del this_rename_column_to
    del this_correct_values_list
    del this_string



#########################################################
#               CREATE BLANK MASTER LISTS               #
#########################################################

dynamic_code.loc[len(dynamic_code.index)] = [398, ' ']
dynamic_code.loc[len(dynamic_code.index)] = [399, '# CREATE BLANK MASTER LISTS']

# use "column_map" "add_values_to_master_list" column
master_lists = column_map['add_values_to_master_list'].dropna().drop_duplicates().to_frame()
master_lists.reset_index(drop=True, inplace=True)  # reset the index after drop_duplicates() or things get messed up

# loop through "master_lists"
for i in range(len(master_lists)):
    this_master_list_name = master_lists['add_values_to_master_list'][i]
    this_ml_name = f'master_list_{this_master_list_name}'

    # Create an empty table
    this_string = f"{this_ml_name} = pandas.DataFrame(columns=['valid_value'])"

    dynamic_code.loc[len(dynamic_code.index)] = [i+400, this_string]   

    del this_master_list_name
    del this_ml_name
    del this_string

del i


#########################################################
#     RUN DYNAMIC IMPORT CODE (prints code below)       #
#########################################################

# sorting a dataframe by a column, need inplace=True or nothing happens
dynamic_code.sort_values(by='run_order', ascending=True, inplace=True)
print(dynamic_code)
dynamic_code.reset_index(drop=True, inplace=True)  # reset the index each time or things get messed up

for i in range(len(dynamic_code)):
    this_line = dynamic_code['run_order'][i]

    if this_line < 798:     # the imports to SQLITE dynamic codes starts at run_order = 798
        print(dynamic_code['code'][i])

        # run the line of code 
        exec(dynamic_code['code'][i])


del i



#########################################################
#                       ADD COLUMNS                     #
#########################################################

# duplicate values if duplicate_existing_column = Y
# otherwise just create blank columns at this stage, so values can be populated after data cleaning is done

new_columns = add_columns[['output_table_name', 'existing_column_name', 'create_new_column_name', 'duplicate_existing_column','value_if_true','value_if_false']].copy().drop_duplicates()

for i in range(len(new_columns)):
    this_output_name = new_columns['output_table_name'][i]
    this_existing_column_name = new_columns['existing_column_name'][i]
    this_create_new_column_name = new_columns['create_new_column_name'][i]  
    this_duplicate_existing_column = new_columns['duplicate_existing_column'][i]  
    this_value_if_true = new_columns['value_if_true'][i]  
    this_value_if_false = new_columns['value_if_false'][i]  

    this_num_columns = len(eval(this_output_name).columns)

    # add the column and DUPLICATE the value from an existing column
    if str(this_duplicate_existing_column).strip() == 'Y':
        eval(this_output_name)[this_create_new_column_name] = eval(this_output_name).loc[:,this_existing_column_name]  # column value = duplicate from existing column

    # add a column with a SPECIFIC value if: value_if_true == value_if_false
    elif str(this_value_if_true).strip() != 'NaN' and str(this_value_if_true).strip() == str(this_value_if_false).strip():
        #print(f"eval({this_output_name}).insert({this_num_columns}, {this_create_new_column_name}, {this_value_if_true}) # column value = this_value_if_true")
        eval(this_output_name).insert(this_num_columns, this_create_new_column_name, this_value_if_true) # column value = this_value_if_true

    # add a blank column
    else:
        eval(this_output_name).insert(this_num_columns, this_create_new_column_name, '') # blank
    
    del this_output_name
    del this_existing_column_name
    del this_create_new_column_name
    del this_duplicate_existing_column
    del this_num_columns
    del this_value_if_true
    del this_value_if_false

del new_columns



#########################################################
#                       CREATE KEYS                     #
#########################################################

print('# CREATING KEY COLUMNS')
print('')

for i in range(len(file_imports)):
    this_output_name = file_imports['output_table_name'][i]
    this_key_column_name = file_imports['key_column_name'][i]
    this_key_column_value = file_imports['key_column_value'][i]


    if str(this_key_column_name) != 'nan':

        this_code = f"eval('{this_output_name}')['{this_key_column_name}'] = "
        #print(this_code)

        this_delimiter_count = this_key_column_value.count('|')
        #print('number of delimiters: ',this_delimiter_count)

        c=0
        this_search_position = 0
        this_string = this_key_column_value

        while c <= this_delimiter_count:
            this_string = this_key_column_value[this_search_position:]
            #print('searching: ',this_string)
            #print('loop: ',c)

            this_delimiter_position = this_string.find('|')
            #print('delimeter positon: ',this_delimiter_position)
            
            if this_delimiter_position == -1:   # final loop will return false (-1) when searchin for a delimiter
                new_string = this_string.lower()
            
            else: 
                new_string = this_string[:this_delimiter_position].lower()
            
            #print('substring: ',new_string)

            this_search_position = this_search_position + this_delimiter_position+1
            #print('updated search position: ',this_search_position)

            if c < this_delimiter_count:
                this_code = f"{this_code} {this_output_name}['{new_string}'].astype(str) + '-' +"

            else:
                this_code = f"{this_code} {this_output_name}['{new_string}'].astype(str)"

            #print(this_code)

            c=c+1

        print(this_code)

        # this will run the string which was created above, as if it was a line of code
        exec(this_code)

        # clean up the newly created key field, remove spaces and make everything lowercase because python is case sensitive
        eval(this_output_name)[this_key_column_name] =  eval(this_output_name)[this_key_column_name].astype(str).str.replace(' +', '', regex = True)      # replace multiple spaces nothing
        eval(this_output_name)[this_key_column_name] =  eval(this_output_name)[this_key_column_name].astype(str).str.replace(' ', '', regex = True)     # replace space nothing

        del this_code
        del c
        del this_search_position
        del this_string

        # Check if they key which has been created is unique
        eval(this_output_name)['TEMP_UNIQUE_KEY'] = eval(this_output_name).groupby(this_key_column_name)[this_key_column_name].transform('count')
        max_key_count = eval(this_output_name)['TEMP_UNIQUE_KEY'].max()
        eval(this_output_name).drop('TEMP_UNIQUE_KEY', axis=1, inplace=True) # drop the count column
        if max_key_count >1:
            print(f'not unique key: {this_output_name}.{this_key_column_name}')

        elif max_key_count == 1:
                    print(f'unique key: {this_output_name}.{this_key_column_name}')

        del max_key_count
    
    del this_output_name
    del this_key_column_name
    del this_key_column_value



#########################################################
# FIX INCORRECT VALUES, THEN CREATE MASTER LISTS FOR QA #
#########################################################


# use the "column_map" excel sheet and "correct_values" excel sheet to find and replace incorrect values 
#   e.g. change name value from 'Bob Brown' to 'Robert Brown'

# loop through "column_map" sheet
for i in range(len(column_map)):
    
    this_output_table_name = column_map['output_table_name'][i]
    this_original_column_name = column_map['original_column_name'][i]    
    this_rename_column_to = column_map['rename_column_to'][i]        
    this_correct_values_list = column_map['correct_values_list'][i]
    this_master_list = column_map['add_values_to_master_list'][i]

    # In case the column was renamed in the previous step
    if str(this_rename_column_to) == 'nan':
        this_col_name = this_original_column_name
    else:
        this_col_name = this_rename_column_to

    # create a list of values to change based on the "correct_values" excel tab, for this row in 'column_map' excel tab
    this_correct_list = correct_values.loc[correct_values['correct_values_list'] == this_correct_values_list]
    
    if str(this_correct_values_list).lower() != 'nan':
       
        this_correct_list.reset_index(drop=True, inplace=True)  # reset the index each time or things get messed up

        # loop though "this_correct_list" and make the changes
        for n in range(len(this_correct_list)):
            this_change_from = this_correct_list['change_from'][n]
            this_change_to = this_correct_list['change_to'][n]

            # do a find and replace (change the values)
            eval(this_output_table_name)[f'{this_col_name}'] = eval(this_output_table_name)[f'{this_col_name}'].replace(to_replace = f'{this_change_from}', value = f'{this_change_to}')

        # UPDATE MASTER LISTS        
        if str(this_master_list).lower() != 'nan':


            # Now that the values have been corrected, create master lists so QA can be done and exceptions can be raised
            this_list = eval(f'master_list_{this_master_list}')  # gets the current list

            new_values = eval(this_output_table_name)[f'{this_col_name}'].to_frame().drop_duplicates()
            new_values.rename(columns = {f'{this_col_name}':'valid_value'}, inplace = True)
            new_values.reset_index(drop=True, inplace=True)  # reset the index each time or things get messed up

            #merge old and new values
            for x in range(len(new_values)):
                this_value = new_values['valid_value'][x]

                if str(this_value).strip() != '' and str(this_value).lower() != 'nan':
                    this_list.loc[len(this_list.index)] = [this_value]   

            # replace the original master list with the merged one
            f'master_list_{this_master_list}' == this_list

            del this_list
            del new_values
            del this_change_from
            del this_change_to
            del this_value

    del this_output_table_name
    del this_original_column_name
    del this_rename_column_to
    del this_correct_values_list
    del this_master_list
    del this_col_name
    del this_correct_list

del i
del n
del x


# RUN QA CHECKS AGAINST THE MASTER LISTS CREATED IN PREVIOUS STEP
exception_list = pandas.DataFrame(columns=['output_table','column_name','exception_value','comment'])

for i in range(len(column_map)):
    
    this_output_table_name = column_map['output_table_name'][i]
    this_original_column_name = column_map['original_column_name'][i]    
    this_rename_column_to = column_map['rename_column_to'][i]        
    this_correct_values_list = column_map['correct_values_list'][i]
    #this_master_list = column_map['add_values_to_master_list'][i]

    # In case the column was renamed in the previous step
    if str(this_rename_column_to) == 'nan':
        this_col_name = this_original_column_name
    else:
        this_col_name = this_rename_column_to

    if str(this_correct_values_list).lower() != 'nan':

        # create a list of all values from the dataset column to check
        this_list_to_check = eval(this_output_table_name)[this_col_name].to_frame().drop_duplicates().dropna()
        this_list_to_check.sort_values(this_col_name, ascending=True, inplace=True)
        this_list_to_check.rename(columns = {this_col_name:'valid_value'}, inplace = True)
        this_list_to_check.reset_index(drop=True, inplace=True)  # reset the index each time or things get messed up

        this_master_list = eval(f'master_list_{this_correct_values_list}')['valid_value'].to_frame().drop_duplicates()
        this_master_list.sort_values('valid_value', ascending=True, inplace=True)
        this_master_list.reset_index(drop=True, inplace=True)  # reset the index each time or things get messed up

        #outer merge the two DataFrames, adding an indicator column called 'Exist'
        this_compare = pandas.merge(this_master_list, this_list_to_check, how='outer', indicator='Exist')

        #find which rows aren't in the master list, and values missing from each table (left_only = masterlist, right_only = table)
        for n in range(len(this_compare)):
            this_value = this_compare['valid_value'][n]
            this_comment = this_compare['Exist'][n]
            
            if str(this_comment) == 'right_only':  # values not in the master list
                print(f'VALUE NOT IN MASTER LIST: {this_value} ({this_output_table_name}.{this_col_name})')
                this_comment = 'NOT IN MASTER LIST'

                exception_list.loc[len(exception_list.index)] = [this_output_table_name, this_col_name, this_value, this_comment]

            elif str(this_comment) == 'left_only':  # values only in the master list 
                this_comment = f'not in this list'

                exception_list.loc[len(exception_list.index)] = [this_output_table_name, this_col_name, this_value, this_comment]

            del this_comment
            del this_value

        del this_output_table_name
        del this_original_column_name
        del this_rename_column_to
        del this_correct_values_list
        del this_col_name
        del this_list_to_check
        del this_master_list
        del this_compare

del i

# export exception list to same folder as code
exception_list.to_excel('import_exception_list.xlsx',index = False)

# copy exception list to sqlite
dataframe_to_sqlite (con, 'exception_list','','')

# UPDATE FLAG COLUMNS (using flag logic in "add_columns" spreadsheet)

flag_columns = add_columns[['output_table_name', 'existing_column_name', 'create_new_column_name', 'search_string', 'value_if_true', 'value_if_false']].copy().drop_duplicates()

for i in range(len(flag_columns)):
    this_output_table_name = flag_columns['output_table_name'][i]
    this_existing_column_name = flag_columns['existing_column_name'][i]
    this_create_new_column_name = flag_columns['create_new_column_name'][i]  
    this_search_string = flag_columns['search_string'][i]  
    this_value_if_true = flag_columns['value_if_true'][i]  
    this_value_if_false = flag_columns['value_if_false'][i]      
    
    if str(this_search_string).strip().lower() != 'nan':    # only run where "search_string" in the "add_columns" spreadsheet is not null
    
        # check for wildcards in searches (wildcard = * symbol)
        if '*' in str(this_search_string):  # contains wildcards
            this_search = str(this_search_string).replace('*','').lower()
        
        else:
            this_search = str(this_search_string).lower().strip()   # no wildcards

        # go the "output table" and apply flag logic
        for n in range(len(eval(this_output_table_name))):  # output table
            this_row_value = eval(this_output_table_name)[this_existing_column_name][n]
            this_row_value = str(this_row_value).lower().strip()    # make lowercase and strip leading and trailing spaces

            if this_search in str(this_row_value): 
                eval(this_output_table_name).at[n,this_create_new_column_name]=this_value_if_true  # TRUE - update the same row's (flag column to "this_value_if_true")
                #print(f'SEARCH TRUE: "{this_row_value}" contains "{this_search}"')

            else:
                eval(this_output_table_name).at[n,this_create_new_column_name]=this_value_if_false  # FALSE - update the same row's (flag column to "this_value_if_false")
                #print(f'SEARCH FALSE: "{this_row_value}" does not contain "{this_search}"')

            del this_row_value

        del this_search

    del this_output_table_name
    del this_existing_column_name
    del this_create_new_column_name
    del this_search_string
    del this_value_if_true
    del this_value_if_false


#########################################################
#           COPY CLEANED DATAFRAMES TO SQLITE           #
#########################################################

# CODE TO IMPORT CLEANED DATAFRAMES TO SQLITE

# sorting a dataframe by a column, need inplace=True or nothing happens
dynamic_code.sort_values(by='run_order', ascending=True, inplace=True)
dynamic_code.reset_index(drop=True, inplace=True)  # reset the index each time or things get messed up

for i in range(len(dynamic_code)):
    this_line = dynamic_code['run_order'][i]

    if this_line >= 798:     # the imports to SQLITE dynamic codes starts at run_order = 798
        print('')
        print(dynamic_code['code'][i])

        # run the line of code 
        exec(dynamic_code['code'][i])

del i


### END FILE IMPORTS ##
